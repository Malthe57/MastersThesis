{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "communities_and_crime = fetch_ucirepo(id=183) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "data = communities_and_crime.data.features \n",
    "y = communities_and_crime.data.targets \n",
    "  \n",
    "# metadata \n",
    "# print(communities_and_crime.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(communities_and_crime.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features containing missing values, except 'state'\n",
    "data = data.drop(data.loc[:, data.columns != 'state'].columns[data.loc[:, data.columns != 'state'].eq('?').any()], axis=1)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['state', 'communityname','fold'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_standardised = scaler.fit_transform(X)\n",
    "\n",
    "X_standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state, group in data.groupby('state'):\n",
    "    print(f\"State {state}:\")\n",
    "    i = 0\n",
    "    for community in group['communityname']:\n",
    "        print(community)\n",
    "        i += 1\n",
    "        if i == 5:\n",
    "            break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "    1: \"Alabama\",\n",
    "    2: \"Alaska\",\n",
    "    4: \"Arizona\",\n",
    "    5: \"Arkansas\",\n",
    "    6: \"California\",\n",
    "    8: \"Colorado\",\n",
    "    9: \"Connecticut\",\n",
    "    10: \"Delaware\",\n",
    "    11: \"DC\",\n",
    "    12: \"Florida\",\n",
    "    13: \"Georgia\",\n",
    "    16: \"Idaho\",\n",
    "    18: \"Indiana\",\n",
    "    19: \"Iowa\",\n",
    "    20: \"Kansas\",\n",
    "    21: \"Kentucky\",\n",
    "    22: \"Louisiana\",\n",
    "    23: \"Maine\",\n",
    "    24: \"Maryland\",\n",
    "    25: \"Massachusetts\",\n",
    "    27: \"Minnesota\",\n",
    "    28: \"Mississippi\",\n",
    "    29: \"Missouri\",\n",
    "    32: \"Nevada\",\n",
    "    33: \"New Hampshire\",\n",
    "    34: \"New Jersey\",\n",
    "    35: \"New Mexico\",\n",
    "    36: \"New York\",\n",
    "    37: \"North Carolina\",\n",
    "    38: \"North Dakota\",\n",
    "    39: \"Ohio\",\n",
    "    40: \"Oklahoma\",\n",
    "    41: \"Oregon\",\n",
    "    42: \"Pennsylvania\",\n",
    "    44: \"Rhode Island\",\n",
    "    45: \"South Carolina\",\n",
    "    46: \"South Dakota\",\n",
    "    47: \"Tennessee\",\n",
    "    48: \"Texas\",\n",
    "    49: \"Utah\",\n",
    "    50: \"Vermont\",\n",
    "    51: \"Virginia\",\n",
    "    53: \"Washington\",\n",
    "    54: \"West Virginia\",\n",
    "    55: \"Wisconsin\",\n",
    "    56: \"Wyoming\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "crime_dict = {}\n",
    "\n",
    "for state, group in data.groupby('state'):\n",
    "    i = np.array(data.loc[data['state'] == state].index)\n",
    "    mean_crime = y.iloc[i].mean().item()\n",
    "    crime_dict[state_dict[state]] = mean_crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Lambert Conformal map of lower 48 states.\n",
    "m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "# draw state boundaries.\n",
    "# data from U.S Census Bureau\n",
    "# http://www.census.gov/geo/www/cob/st2000.html\n",
    "shp_info = m.readshapefile('st99_d00','states',drawbounds=True)\n",
    "# population density by state from\n",
    "# http://en.wikipedia.org/wiki/List_of_U.S._states_by_population_density\n",
    "\n",
    "# choose a color for each state based on population density.\n",
    "colors={}\n",
    "statenames=[]\n",
    "cmap = plt.cm.hot_r # use 'hot' colormap\n",
    "vmin = 0; vmax = 1 # set range.\n",
    "for shapedict in m.states_info:\n",
    "    statename = shapedict['NAME']\n",
    "    # skip DC and Puerto Rico.\n",
    "    if statename in crime_dict.keys():\n",
    "        crime = crime_dict[statename]\n",
    "        # calling colormap with value between 0 and 1 returns\n",
    "        # rgba value.  Invert color range (hot colors are high\n",
    "        # population), take sqrt root to spread out colors more.\n",
    "        colors[statename] = cmap((crime - vmin)/(vmax-vmin))[:3]\n",
    "    statenames.append(statename)\n",
    "# cycle through state names, color each one.\n",
    "ax = plt.gca() # get current axes instance\n",
    "for nshape,seg in enumerate(m.states):\n",
    "    # skip DC and Puerto Rico.\n",
    "    if statenames[nshape] in crime_dict.keys():\n",
    "    # Offset Alaska and Hawaii to the lower-left corner. \n",
    "        if statenames[nshape] == 'Alaska':\n",
    "        # Alaska is too big. Scale it down to 35% first, then transate it. \n",
    "            seg = list(map(lambda coord: (0.35*coord[0] + 1100000, 0.35*coord[1]-1440000), seg))\n",
    "\n",
    "        color = rgb2hex(colors[statenames[nshape]]) \n",
    "        poly = Polygon(seg,facecolor=color,edgecolor=color)\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "# Create a ScalarMappable object for colormap normalization\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation='vertical')\n",
    "cbar.set_label('Violent crimes')\n",
    "\n",
    "plt.title('US States by Violent crimes per population')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
